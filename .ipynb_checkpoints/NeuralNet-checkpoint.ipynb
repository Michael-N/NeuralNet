{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net \n",
    "- Code By Michael Sherif Naguib\n",
    "- license: MIT open source\n",
    "- Date: 6/10/19\n",
    "- @University of Tulsa\n",
    "- Description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a comment\n",
    "import keras\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import random\n",
    "from NumLib import PlotUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\socce\\AppData\\Local\\Continuum\\anaconda3\\envs\\General\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model.add(keras.layers.Dense(units=2, activation='sigmoid', input_dim=2))\n",
    "model.add(keras.layers.Dense(units=2, activation='sigmoid'))\n",
    "model.add(keras.layers.Dense(units=2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net!\n",
    "- this neural net will be trained on solving: xor,nand,or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OR(a,b):\n",
    "    return  1 if a or b else 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'keras' from 'C:\\\\Users\\\\socce\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\envs\\\\General\\\\lib\\\\site-packages\\\\keras\\\\__init__.py'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 5 is out of bounds for axis 1 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-81d7f7292c38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\General\\lib\\site-packages\\keras\\utils\\np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[1;34m(y, num_classes, dtype)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mcategorical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mcategorical\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[0moutput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mcategorical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 5 is out of bounds for axis 1 with size 2"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_test=[]\n",
    "y_test=[]\n",
    "\n",
    "for i in range(0,100000):\n",
    "    a = random.randint(0,1)\n",
    "    b = random.randint(0,1)\n",
    "    x_train.append(np.array([a,b]))\n",
    "    y_train.append(OR(a,b))\n",
    "\n",
    "for i in range(0,500):\n",
    "    a = random.randint(0,1)\n",
    "    b = random.randint(0,1)\n",
    "    x_test.append(np.array([a,b]))\n",
    "    y_test.append(np.array(OR(a,b)))\n",
    "\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "x_train = np.array(x_train)\n",
    "\n",
    "y_test = keras.utils.to_categorical(np.array(y_test),num_classes=2)\n",
    "y_train = keras.utils.to_categorical(np.array(y_train),num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\socce\\AppData\\Local\\Continuum\\anaconda3\\envs\\General\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/9\n",
      "100000/100000 [==============================] - ETA: 36:31 - loss: 0.5801 - acc: 0.90 - ETA: 1:12 - loss: 0.6202 - acc: 0.7471 - ETA: 37s - loss: 0.6199 - acc: 0.735 - ETA: 26s - loss: 0.6155 - acc: 0.73 - ETA: 21s - loss: 0.6098 - acc: 0.74 - ETA: 17s - loss: 0.6039 - acc: 0.74 - ETA: 15s - loss: 0.6003 - acc: 0.75 - ETA: 13s - loss: 0.5966 - acc: 0.75 - ETA: 12s - loss: 0.5929 - acc: 0.75 - ETA: 11s - loss: 0.5928 - acc: 0.74 - ETA: 10s - loss: 0.5896 - acc: 0.75 - ETA: 9s - loss: 0.5883 - acc: 0.7503 - ETA: 9s - loss: 0.5866 - acc: 0.750 - ETA: 8s - loss: 0.5854 - acc: 0.749 - ETA: 8s - loss: 0.5840 - acc: 0.748 - ETA: 7s - loss: 0.5816 - acc: 0.750 - ETA: 7s - loss: 0.5798 - acc: 0.750 - ETA: 7s - loss: 0.5774 - acc: 0.751 - ETA: 6s - loss: 0.5750 - acc: 0.752 - ETA: 6s - loss: 0.5729 - acc: 0.753 - ETA: 6s - loss: 0.5725 - acc: 0.753 - ETA: 5s - loss: 0.5715 - acc: 0.753 - ETA: 5s - loss: 0.5709 - acc: 0.752 - ETA: 5s - loss: 0.5689 - acc: 0.754 - ETA: 5s - loss: 0.5686 - acc: 0.753 - ETA: 5s - loss: 0.5683 - acc: 0.753 - ETA: 5s - loss: 0.5681 - acc: 0.752 - ETA: 5s - loss: 0.5680 - acc: 0.752 - ETA: 4s - loss: 0.5672 - acc: 0.752 - ETA: 4s - loss: 0.5668 - acc: 0.752 - ETA: 4s - loss: 0.5667 - acc: 0.751 - ETA: 4s - loss: 0.5661 - acc: 0.751 - ETA: 4s - loss: 0.5658 - acc: 0.751 - ETA: 4s - loss: 0.5658 - acc: 0.751 - ETA: 4s - loss: 0.5651 - acc: 0.751 - ETA: 4s - loss: 0.5648 - acc: 0.751 - ETA: 4s - loss: 0.5644 - acc: 0.751 - ETA: 4s - loss: 0.5641 - acc: 0.751 - ETA: 3s - loss: 0.5641 - acc: 0.751 - ETA: 3s - loss: 0.5642 - acc: 0.750 - ETA: 3s - loss: 0.5634 - acc: 0.751 - ETA: 3s - loss: 0.5633 - acc: 0.750 - ETA: 3s - loss: 0.5627 - acc: 0.751 - ETA: 3s - loss: 0.5628 - acc: 0.750 - ETA: 3s - loss: 0.5632 - acc: 0.750 - ETA: 3s - loss: 0.5631 - acc: 0.749 - ETA: 3s - loss: 0.5626 - acc: 0.750 - ETA: 3s - loss: 0.5618 - acc: 0.750 - ETA: 2s - loss: 0.5616 - acc: 0.750 - ETA: 2s - loss: 0.5614 - acc: 0.750 - ETA: 2s - loss: 0.5607 - acc: 0.750 - ETA: 2s - loss: 0.5607 - acc: 0.750 - ETA: 2s - loss: 0.5604 - acc: 0.750 - ETA: 2s - loss: 0.5600 - acc: 0.750 - ETA: 2s - loss: 0.5597 - acc: 0.750 - ETA: 2s - loss: 0.5596 - acc: 0.750 - ETA: 2s - loss: 0.5594 - acc: 0.750 - ETA: 2s - loss: 0.5595 - acc: 0.750 - ETA: 2s - loss: 0.5597 - acc: 0.750 - ETA: 2s - loss: 0.5591 - acc: 0.750 - ETA: 2s - loss: 0.5589 - acc: 0.750 - ETA: 1s - loss: 0.5583 - acc: 0.751 - ETA: 1s - loss: 0.5579 - acc: 0.751 - ETA: 1s - loss: 0.5579 - acc: 0.751 - ETA: 1s - loss: 0.5577 - acc: 0.751 - ETA: 1s - loss: 0.5573 - acc: 0.751 - ETA: 1s - loss: 0.5568 - acc: 0.751 - ETA: 1s - loss: 0.5565 - acc: 0.751 - ETA: 1s - loss: 0.5562 - acc: 0.751 - ETA: 1s - loss: 0.5558 - acc: 0.752 - ETA: 1s - loss: 0.5560 - acc: 0.751 - ETA: 1s - loss: 0.5561 - acc: 0.751 - ETA: 1s - loss: 0.5561 - acc: 0.751 - ETA: 1s - loss: 0.5559 - acc: 0.751 - ETA: 1s - loss: 0.5559 - acc: 0.751 - ETA: 1s - loss: 0.5559 - acc: 0.751 - ETA: 0s - loss: 0.5560 - acc: 0.751 - ETA: 0s - loss: 0.5555 - acc: 0.751 - ETA: 0s - loss: 0.5553 - acc: 0.751 - ETA: 0s - loss: 0.5552 - acc: 0.751 - ETA: 0s - loss: 0.5550 - acc: 0.751 - ETA: 0s - loss: 0.5547 - acc: 0.751 - ETA: 0s - loss: 0.5546 - acc: 0.751 - ETA: 0s - loss: 0.5544 - acc: 0.751 - ETA: 0s - loss: 0.5543 - acc: 0.751 - ETA: 0s - loss: 0.5545 - acc: 0.751 - ETA: 0s - loss: 0.5545 - acc: 0.751 - ETA: 0s - loss: 0.5541 - acc: 0.751 - ETA: 0s - loss: 0.5539 - acc: 0.751 - ETA: 0s - loss: 0.5541 - acc: 0.751 - ETA: 0s - loss: 0.5538 - acc: 0.751 - ETA: 0s - loss: 0.5538 - acc: 0.751 - ETA: 0s - loss: 0.5537 - acc: 0.751 - 5s 55us/step - loss: 0.5535 - acc: 0.7517\n",
      "Epoch 2/9\n",
      "100000/100000 [==============================] - ETA: 31s - loss: 0.5792 - acc: 0.71 - ETA: 6s - loss: 0.5465 - acc: 0.7478 - ETA: 5s - loss: 0.5425 - acc: 0.751 - ETA: 5s - loss: 0.5538 - acc: 0.741 - ETA: 5s - loss: 0.5496 - acc: 0.745 - ETA: 5s - loss: 0.5474 - acc: 0.747 - ETA: 5s - loss: 0.5495 - acc: 0.745 - ETA: 5s - loss: 0.5492 - acc: 0.745 - ETA: 5s - loss: 0.5517 - acc: 0.743 - ETA: 5s - loss: 0.5548 - acc: 0.740 - ETA: 5s - loss: 0.5536 - acc: 0.741 - ETA: 5s - loss: 0.5527 - acc: 0.742 - ETA: 4s - loss: 0.5519 - acc: 0.742 - ETA: 4s - loss: 0.5514 - acc: 0.743 - ETA: 4s - loss: 0.5501 - acc: 0.744 - ETA: 4s - loss: 0.5497 - acc: 0.744 - ETA: 4s - loss: 0.5483 - acc: 0.745 - ETA: 4s - loss: 0.5476 - acc: 0.746 - ETA: 4s - loss: 0.5476 - acc: 0.746 - ETA: 4s - loss: 0.5474 - acc: 0.746 - ETA: 4s - loss: 0.5478 - acc: 0.746 - ETA: 4s - loss: 0.5471 - acc: 0.746 - ETA: 4s - loss: 0.5453 - acc: 0.748 - ETA: 4s - loss: 0.5445 - acc: 0.748 - ETA: 3s - loss: 0.5443 - acc: 0.748 - ETA: 3s - loss: 0.5442 - acc: 0.748 - ETA: 3s - loss: 0.5443 - acc: 0.748 - ETA: 3s - loss: 0.5436 - acc: 0.749 - ETA: 3s - loss: 0.5439 - acc: 0.748 - ETA: 3s - loss: 0.5432 - acc: 0.749 - ETA: 3s - loss: 0.5429 - acc: 0.749 - ETA: 3s - loss: 0.5428 - acc: 0.749 - ETA: 3s - loss: 0.5424 - acc: 0.749 - ETA: 3s - loss: 0.5420 - acc: 0.750 - ETA: 3s - loss: 0.5417 - acc: 0.750 - ETA: 3s - loss: 0.5419 - acc: 0.750 - ETA: 3s - loss: 0.5417 - acc: 0.750 - ETA: 3s - loss: 0.5422 - acc: 0.749 - ETA: 2s - loss: 0.5420 - acc: 0.749 - ETA: 2s - loss: 0.5418 - acc: 0.749 - ETA: 2s - loss: 0.5414 - acc: 0.750 - ETA: 2s - loss: 0.5417 - acc: 0.749 - ETA: 2s - loss: 0.5409 - acc: 0.750 - ETA: 2s - loss: 0.5408 - acc: 0.750 - ETA: 2s - loss: 0.5403 - acc: 0.750 - ETA: 2s - loss: 0.5396 - acc: 0.751 - ETA: 2s - loss: 0.5398 - acc: 0.750 - ETA: 2s - loss: 0.5396 - acc: 0.750 - ETA: 2s - loss: 0.5396 - acc: 0.750 - ETA: 2s - loss: 0.5397 - acc: 0.750 - ETA: 2s - loss: 0.5394 - acc: 0.750 - ETA: 2s - loss: 0.5392 - acc: 0.750 - ETA: 2s - loss: 0.5388 - acc: 0.751 - ETA: 2s - loss: 0.5386 - acc: 0.751 - ETA: 2s - loss: 0.5382 - acc: 0.751 - ETA: 1s - loss: 0.5378 - acc: 0.751 - ETA: 1s - loss: 0.5376 - acc: 0.751 - ETA: 1s - loss: 0.5379 - acc: 0.751 - ETA: 1s - loss: 0.5376 - acc: 0.751 - ETA: 1s - loss: 0.5375 - acc: 0.751 - ETA: 1s - loss: 0.5374 - acc: 0.751 - ETA: 1s - loss: 0.5371 - acc: 0.751 - ETA: 1s - loss: 0.5369 - acc: 0.751 - ETA: 1s - loss: 0.5369 - acc: 0.751 - ETA: 1s - loss: 0.5369 - acc: 0.751 - ETA: 1s - loss: 0.5366 - acc: 0.751 - ETA: 1s - loss: 0.5362 - acc: 0.751 - ETA: 1s - loss: 0.5362 - acc: 0.751 - ETA: 1s - loss: 0.5361 - acc: 0.751 - ETA: 1s - loss: 0.5357 - acc: 0.752 - ETA: 1s - loss: 0.5357 - acc: 0.751 - ETA: 1s - loss: 0.5353 - acc: 0.752 - ETA: 1s - loss: 0.5350 - acc: 0.752 - ETA: 0s - loss: 0.5351 - acc: 0.752 - ETA: 0s - loss: 0.5351 - acc: 0.751 - ETA: 0s - loss: 0.5350 - acc: 0.751 - ETA: 0s - loss: 0.5350 - acc: 0.751 - ETA: 0s - loss: 0.5348 - acc: 0.751 - ETA: 0s - loss: 0.5352 - acc: 0.751 - ETA: 0s - loss: 0.5354 - acc: 0.750 - ETA: 0s - loss: 0.5351 - acc: 0.751 - ETA: 0s - loss: 0.5348 - acc: 0.751 - ETA: 0s - loss: 0.5348 - acc: 0.750 - ETA: 0s - loss: 0.5342 - acc: 0.751 - ETA: 0s - loss: 0.5341 - acc: 0.751 - ETA: 0s - loss: 0.5338 - acc: 0.751 - ETA: 0s - loss: 0.5338 - acc: 0.751 - ETA: 0s - loss: 0.5335 - acc: 0.751 - ETA: 0s - loss: 0.5334 - acc: 0.751 - ETA: 0s - loss: 0.5331 - acc: 0.751 - ETA: 0s - loss: 0.5329 - acc: 0.751 - ETA: 0s - loss: 0.5328 - acc: 0.751 - ETA: 0s - loss: 0.5324 - acc: 0.751 - 5s 47us/step - loss: 0.5324 - acc: 0.7517\n",
      "Epoch 3/9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - ETA: 31s - loss: 0.5487 - acc: 0.71 - ETA: 5s - loss: 0.5469 - acc: 0.7216 - ETA: 5s - loss: 0.5246 - acc: 0.743 - ETA: 4s - loss: 0.5205 - acc: 0.746 - ETA: 4s - loss: 0.5172 - acc: 0.749 - ETA: 4s - loss: 0.5151 - acc: 0.751 - ETA: 4s - loss: 0.5090 - acc: 0.757 - ETA: 4s - loss: 0.5094 - acc: 0.756 - ETA: 4s - loss: 0.5098 - acc: 0.755 - ETA: 4s - loss: 0.5134 - acc: 0.752 - ETA: 4s - loss: 0.5143 - acc: 0.750 - ETA: 4s - loss: 0.5145 - acc: 0.750 - ETA: 4s - loss: 0.5145 - acc: 0.750 - ETA: 4s - loss: 0.5147 - acc: 0.749 - ETA: 3s - loss: 0.5126 - acc: 0.751 - ETA: 3s - loss: 0.5134 - acc: 0.750 - ETA: 3s - loss: 0.5131 - acc: 0.750 - ETA: 3s - loss: 0.5112 - acc: 0.751 - ETA: 3s - loss: 0.5102 - acc: 0.752 - ETA: 3s - loss: 0.5115 - acc: 0.750 - ETA: 3s - loss: 0.5100 - acc: 0.751 - ETA: 3s - loss: 0.5109 - acc: 0.750 - ETA: 3s - loss: 0.5109 - acc: 0.750 - ETA: 3s - loss: 0.5115 - acc: 0.749 - ETA: 3s - loss: 0.5107 - acc: 0.749 - ETA: 3s - loss: 0.5105 - acc: 0.749 - ETA: 3s - loss: 0.5095 - acc: 0.750 - ETA: 3s - loss: 0.5094 - acc: 0.749 - ETA: 3s - loss: 0.5090 - acc: 0.749 - ETA: 2s - loss: 0.5083 - acc: 0.750 - ETA: 2s - loss: 0.5076 - acc: 0.750 - ETA: 2s - loss: 0.5072 - acc: 0.750 - ETA: 2s - loss: 0.5067 - acc: 0.750 - ETA: 2s - loss: 0.5066 - acc: 0.750 - ETA: 2s - loss: 0.5068 - acc: 0.749 - ETA: 2s - loss: 0.5067 - acc: 0.749 - ETA: 2s - loss: 0.5060 - acc: 0.749 - ETA: 2s - loss: 0.5060 - acc: 0.749 - ETA: 2s - loss: 0.5056 - acc: 0.749 - ETA: 2s - loss: 0.5050 - acc: 0.749 - ETA: 2s - loss: 0.5046 - acc: 0.749 - ETA: 2s - loss: 0.5037 - acc: 0.749 - ETA: 2s - loss: 0.5033 - acc: 0.749 - ETA: 2s - loss: 0.5031 - acc: 0.749 - ETA: 2s - loss: 0.5024 - acc: 0.749 - ETA: 2s - loss: 0.5019 - acc: 0.749 - ETA: 2s - loss: 0.5014 - acc: 0.749 - ETA: 2s - loss: 0.5006 - acc: 0.750 - ETA: 1s - loss: 0.5000 - acc: 0.750 - ETA: 1s - loss: 0.4995 - acc: 0.750 - ETA: 1s - loss: 0.4989 - acc: 0.750 - ETA: 1s - loss: 0.4986 - acc: 0.750 - ETA: 1s - loss: 0.4983 - acc: 0.749 - ETA: 1s - loss: 0.4977 - acc: 0.749 - ETA: 1s - loss: 0.4972 - acc: 0.749 - ETA: 1s - loss: 0.4965 - acc: 0.750 - ETA: 1s - loss: 0.4956 - acc: 0.750 - ETA: 1s - loss: 0.4948 - acc: 0.750 - ETA: 1s - loss: 0.4943 - acc: 0.750 - ETA: 1s - loss: 0.4935 - acc: 0.750 - ETA: 1s - loss: 0.4929 - acc: 0.750 - ETA: 1s - loss: 0.4925 - acc: 0.750 - ETA: 1s - loss: 0.4915 - acc: 0.751 - ETA: 1s - loss: 0.4911 - acc: 0.751 - ETA: 1s - loss: 0.4901 - acc: 0.751 - ETA: 1s - loss: 0.4896 - acc: 0.751 - ETA: 0s - loss: 0.4891 - acc: 0.751 - ETA: 0s - loss: 0.4885 - acc: 0.751 - ETA: 0s - loss: 0.4879 - acc: 0.751 - ETA: 0s - loss: 0.4870 - acc: 0.751 - ETA: 0s - loss: 0.4866 - acc: 0.751 - ETA: 0s - loss: 0.4859 - acc: 0.751 - ETA: 0s - loss: 0.4851 - acc: 0.751 - ETA: 0s - loss: 0.4845 - acc: 0.751 - ETA: 0s - loss: 0.4836 - acc: 0.751 - ETA: 0s - loss: 0.4829 - acc: 0.751 - ETA: 0s - loss: 0.4819 - acc: 0.752 - ETA: 0s - loss: 0.4813 - acc: 0.752 - ETA: 0s - loss: 0.4809 - acc: 0.751 - ETA: 0s - loss: 0.4801 - acc: 0.751 - ETA: 0s - loss: 0.4794 - acc: 0.751 - ETA: 0s - loss: 0.4788 - acc: 0.751 - ETA: 0s - loss: 0.4782 - acc: 0.751 - ETA: 0s - loss: 0.4776 - acc: 0.751 - ETA: 0s - loss: 0.4768 - acc: 0.751 - 4s 43us/step - loss: 0.4759 - acc: 0.7517\n",
      "Epoch 4/9\n",
      "100000/100000 [==============================] - ETA: 28s - loss: 0.4145 - acc: 0.75 - ETA: 5s - loss: 0.4029 - acc: 0.7639 - ETA: 4s - loss: 0.4069 - acc: 0.756 - ETA: 4s - loss: 0.4083 - acc: 0.753 - ETA: 4s - loss: 0.4065 - acc: 0.754 - ETA: 4s - loss: 0.4048 - acc: 0.755 - ETA: 4s - loss: 0.4024 - acc: 0.756 - ETA: 4s - loss: 0.4024 - acc: 0.755 - ETA: 4s - loss: 0.4030 - acc: 0.753 - ETA: 4s - loss: 0.4016 - acc: 0.753 - ETA: 3s - loss: 0.4001 - acc: 0.754 - ETA: 3s - loss: 0.3992 - acc: 0.754 - ETA: 3s - loss: 0.3982 - acc: 0.753 - ETA: 3s - loss: 0.3968 - acc: 0.754 - ETA: 3s - loss: 0.3955 - acc: 0.754 - ETA: 3s - loss: 0.3939 - acc: 0.754 - ETA: 3s - loss: 0.3942 - acc: 0.752 - ETA: 3s - loss: 0.3932 - acc: 0.752 - ETA: 3s - loss: 0.3908 - acc: 0.753 - ETA: 3s - loss: 0.3898 - acc: 0.753 - ETA: 3s - loss: 0.3887 - acc: 0.753 - ETA: 3s - loss: 0.3879 - acc: 0.752 - ETA: 3s - loss: 0.3869 - acc: 0.751 - ETA: 3s - loss: 0.3856 - acc: 0.752 - ETA: 3s - loss: 0.3843 - acc: 0.752 - ETA: 3s - loss: 0.3833 - acc: 0.751 - ETA: 3s - loss: 0.3820 - acc: 0.751 - ETA: 2s - loss: 0.3808 - acc: 0.751 - ETA: 2s - loss: 0.3790 - acc: 0.752 - ETA: 2s - loss: 0.3776 - acc: 0.752 - ETA: 2s - loss: 0.3765 - acc: 0.752 - ETA: 2s - loss: 0.3745 - acc: 0.753 - ETA: 2s - loss: 0.3729 - acc: 0.753 - ETA: 2s - loss: 0.3716 - acc: 0.754 - ETA: 2s - loss: 0.3702 - acc: 0.754 - ETA: 2s - loss: 0.3690 - acc: 0.754 - ETA: 2s - loss: 0.3677 - acc: 0.754 - ETA: 2s - loss: 0.3665 - acc: 0.754 - ETA: 2s - loss: 0.3651 - acc: 0.754 - ETA: 2s - loss: 0.3640 - acc: 0.753 - ETA: 2s - loss: 0.3628 - acc: 0.753 - ETA: 2s - loss: 0.3616 - acc: 0.753 - ETA: 2s - loss: 0.3600 - acc: 0.754 - ETA: 2s - loss: 0.3587 - acc: 0.754 - ETA: 2s - loss: 0.3575 - acc: 0.753 - ETA: 2s - loss: 0.3561 - acc: 0.753 - ETA: 2s - loss: 0.3545 - acc: 0.754 - ETA: 2s - loss: 0.3533 - acc: 0.755 - ETA: 1s - loss: 0.3520 - acc: 0.760 - ETA: 1s - loss: 0.3507 - acc: 0.765 - ETA: 1s - loss: 0.3495 - acc: 0.769 - ETA: 1s - loss: 0.3485 - acc: 0.774 - ETA: 1s - loss: 0.3471 - acc: 0.778 - ETA: 1s - loss: 0.3457 - acc: 0.782 - ETA: 1s - loss: 0.3446 - acc: 0.786 - ETA: 1s - loss: 0.3434 - acc: 0.790 - ETA: 1s - loss: 0.3421 - acc: 0.793 - ETA: 1s - loss: 0.3407 - acc: 0.797 - ETA: 1s - loss: 0.3391 - acc: 0.801 - ETA: 1s - loss: 0.3378 - acc: 0.804 - ETA: 1s - loss: 0.3365 - acc: 0.808 - ETA: 1s - loss: 0.3348 - acc: 0.811 - ETA: 1s - loss: 0.3332 - acc: 0.815 - ETA: 1s - loss: 0.3319 - acc: 0.818 - ETA: 1s - loss: 0.3304 - acc: 0.821 - ETA: 1s - loss: 0.3291 - acc: 0.823 - ETA: 1s - loss: 0.3277 - acc: 0.826 - ETA: 0s - loss: 0.3263 - acc: 0.829 - ETA: 0s - loss: 0.3248 - acc: 0.832 - ETA: 0s - loss: 0.3233 - acc: 0.834 - ETA: 0s - loss: 0.3218 - acc: 0.837 - ETA: 0s - loss: 0.3204 - acc: 0.839 - ETA: 0s - loss: 0.3192 - acc: 0.841 - ETA: 0s - loss: 0.3179 - acc: 0.843 - ETA: 0s - loss: 0.3164 - acc: 0.845 - ETA: 0s - loss: 0.3151 - acc: 0.848 - ETA: 0s - loss: 0.3136 - acc: 0.850 - ETA: 0s - loss: 0.3121 - acc: 0.852 - ETA: 0s - loss: 0.3106 - acc: 0.854 - ETA: 0s - loss: 0.3092 - acc: 0.856 - ETA: 0s - loss: 0.3078 - acc: 0.857 - ETA: 0s - loss: 0.3063 - acc: 0.859 - ETA: 0s - loss: 0.3049 - acc: 0.861 - ETA: 0s - loss: 0.3035 - acc: 0.863 - ETA: 0s - loss: 0.3020 - acc: 0.864 - ETA: 0s - loss: 0.3006 - acc: 0.866 - 4s 44us/step - loss: 0.3003 - acc: 0.8669\n",
      "Epoch 5/9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - ETA: 28s - loss: 0.1630 - acc: 1.00 - ETA: 4s - loss: 0.1822 - acc: 1.0000 - ETA: 4s - loss: 0.1822 - acc: 1.000 - ETA: 4s - loss: 0.1811 - acc: 1.000 - ETA: 3s - loss: 0.1787 - acc: 1.000 - ETA: 3s - loss: 0.1776 - acc: 1.000 - ETA: 3s - loss: 0.1756 - acc: 1.000 - ETA: 3s - loss: 0.1751 - acc: 1.000 - ETA: 3s - loss: 0.1737 - acc: 1.000 - ETA: 3s - loss: 0.1733 - acc: 1.000 - ETA: 3s - loss: 0.1725 - acc: 1.000 - ETA: 3s - loss: 0.1719 - acc: 1.000 - ETA: 3s - loss: 0.1705 - acc: 1.000 - ETA: 3s - loss: 0.1698 - acc: 1.000 - ETA: 3s - loss: 0.1688 - acc: 1.000 - ETA: 3s - loss: 0.1676 - acc: 1.000 - ETA: 3s - loss: 0.1665 - acc: 1.000 - ETA: 3s - loss: 0.1654 - acc: 1.000 - ETA: 3s - loss: 0.1646 - acc: 1.000 - ETA: 3s - loss: 0.1637 - acc: 1.000 - ETA: 3s - loss: 0.1629 - acc: 1.000 - ETA: 3s - loss: 0.1620 - acc: 1.000 - ETA: 3s - loss: 0.1611 - acc: 1.000 - ETA: 3s - loss: 0.1602 - acc: 1.000 - ETA: 2s - loss: 0.1592 - acc: 1.000 - ETA: 2s - loss: 0.1582 - acc: 1.000 - ETA: 2s - loss: 0.1574 - acc: 1.000 - ETA: 2s - loss: 0.1564 - acc: 1.000 - ETA: 2s - loss: 0.1554 - acc: 1.000 - ETA: 2s - loss: 0.1545 - acc: 1.000 - ETA: 2s - loss: 0.1536 - acc: 1.000 - ETA: 2s - loss: 0.1526 - acc: 1.000 - ETA: 2s - loss: 0.1518 - acc: 1.000 - ETA: 2s - loss: 0.1511 - acc: 1.000 - ETA: 2s - loss: 0.1506 - acc: 1.000 - ETA: 2s - loss: 0.1501 - acc: 1.000 - ETA: 2s - loss: 0.1493 - acc: 1.000 - ETA: 2s - loss: 0.1486 - acc: 1.000 - ETA: 2s - loss: 0.1480 - acc: 1.000 - ETA: 2s - loss: 0.1474 - acc: 1.000 - ETA: 2s - loss: 0.1467 - acc: 1.000 - ETA: 2s - loss: 0.1460 - acc: 1.000 - ETA: 2s - loss: 0.1454 - acc: 1.000 - ETA: 2s - loss: 0.1449 - acc: 1.000 - ETA: 2s - loss: 0.1443 - acc: 1.000 - ETA: 2s - loss: 0.1436 - acc: 1.000 - ETA: 2s - loss: 0.1427 - acc: 1.000 - ETA: 2s - loss: 0.1418 - acc: 1.000 - ETA: 2s - loss: 0.1410 - acc: 1.000 - ETA: 1s - loss: 0.1403 - acc: 1.000 - ETA: 1s - loss: 0.1395 - acc: 1.000 - ETA: 1s - loss: 0.1389 - acc: 1.000 - ETA: 1s - loss: 0.1381 - acc: 1.000 - ETA: 1s - loss: 0.1373 - acc: 1.000 - ETA: 1s - loss: 0.1366 - acc: 1.000 - ETA: 1s - loss: 0.1359 - acc: 1.000 - ETA: 1s - loss: 0.1353 - acc: 1.000 - ETA: 1s - loss: 0.1346 - acc: 1.000 - ETA: 1s - loss: 0.1339 - acc: 1.000 - ETA: 1s - loss: 0.1333 - acc: 1.000 - ETA: 1s - loss: 0.1328 - acc: 1.000 - ETA: 1s - loss: 0.1323 - acc: 1.000 - ETA: 1s - loss: 0.1318 - acc: 1.000 - ETA: 1s - loss: 0.1314 - acc: 1.000 - ETA: 1s - loss: 0.1309 - acc: 1.000 - ETA: 1s - loss: 0.1304 - acc: 1.000 - ETA: 1s - loss: 0.1298 - acc: 1.000 - ETA: 1s - loss: 0.1293 - acc: 1.000 - ETA: 1s - loss: 0.1286 - acc: 1.000 - ETA: 1s - loss: 0.1281 - acc: 1.000 - ETA: 0s - loss: 0.1277 - acc: 1.000 - ETA: 0s - loss: 0.1273 - acc: 1.000 - ETA: 0s - loss: 0.1269 - acc: 1.000 - ETA: 0s - loss: 0.1265 - acc: 1.000 - ETA: 0s - loss: 0.1260 - acc: 1.000 - ETA: 0s - loss: 0.1256 - acc: 1.000 - ETA: 0s - loss: 0.1251 - acc: 1.000 - ETA: 0s - loss: 0.1246 - acc: 1.000 - ETA: 0s - loss: 0.1241 - acc: 1.000 - ETA: 0s - loss: 0.1236 - acc: 1.000 - ETA: 0s - loss: 0.1229 - acc: 1.000 - ETA: 0s - loss: 0.1224 - acc: 1.000 - ETA: 0s - loss: 0.1219 - acc: 1.000 - ETA: 0s - loss: 0.1212 - acc: 1.000 - ETA: 0s - loss: 0.1206 - acc: 1.000 - ETA: 0s - loss: 0.1200 - acc: 1.000 - ETA: 0s - loss: 0.1194 - acc: 1.000 - ETA: 0s - loss: 0.1189 - acc: 1.000 - ETA: 0s - loss: 0.1183 - acc: 1.000 - ETA: 0s - loss: 0.1177 - acc: 1.000 - 5s 46us/step - loss: 0.1173 - acc: 1.0000\n",
      "Epoch 6/9\n",
      "100000/100000 [==============================] - ETA: 31s - loss: 0.0510 - acc: 1.00 - ETA: 4s - loss: 0.0697 - acc: 1.0000 - ETA: 4s - loss: 0.0703 - acc: 1.000 - ETA: 3s - loss: 0.0709 - acc: 1.000 - ETA: 3s - loss: 0.0707 - acc: 1.000 - ETA: 3s - loss: 0.0703 - acc: 1.000 - ETA: 3s - loss: 0.0699 - acc: 1.000 - ETA: 3s - loss: 0.0696 - acc: 1.000 - ETA: 3s - loss: 0.0692 - acc: 1.000 - ETA: 3s - loss: 0.0690 - acc: 1.000 - ETA: 3s - loss: 0.0686 - acc: 1.000 - ETA: 3s - loss: 0.0683 - acc: 1.000 - ETA: 3s - loss: 0.0681 - acc: 1.000 - ETA: 3s - loss: 0.0679 - acc: 1.000 - ETA: 3s - loss: 0.0675 - acc: 1.000 - ETA: 3s - loss: 0.0673 - acc: 1.000 - ETA: 3s - loss: 0.0670 - acc: 1.000 - ETA: 3s - loss: 0.0668 - acc: 1.000 - ETA: 3s - loss: 0.0665 - acc: 1.000 - ETA: 3s - loss: 0.0662 - acc: 1.000 - ETA: 3s - loss: 0.0659 - acc: 1.000 - ETA: 2s - loss: 0.0656 - acc: 1.000 - ETA: 2s - loss: 0.0652 - acc: 1.000 - ETA: 2s - loss: 0.0650 - acc: 1.000 - ETA: 2s - loss: 0.0648 - acc: 1.000 - ETA: 2s - loss: 0.0646 - acc: 1.000 - ETA: 2s - loss: 0.0643 - acc: 1.000 - ETA: 2s - loss: 0.0640 - acc: 1.000 - ETA: 2s - loss: 0.0637 - acc: 1.000 - ETA: 2s - loss: 0.0634 - acc: 1.000 - ETA: 2s - loss: 0.0631 - acc: 1.000 - ETA: 2s - loss: 0.0628 - acc: 1.000 - ETA: 2s - loss: 0.0625 - acc: 1.000 - ETA: 2s - loss: 0.0623 - acc: 1.000 - ETA: 2s - loss: 0.0620 - acc: 1.000 - ETA: 2s - loss: 0.0617 - acc: 1.000 - ETA: 2s - loss: 0.0615 - acc: 1.000 - ETA: 2s - loss: 0.0612 - acc: 1.000 - ETA: 2s - loss: 0.0610 - acc: 1.000 - ETA: 2s - loss: 0.0608 - acc: 1.000 - ETA: 1s - loss: 0.0606 - acc: 1.000 - ETA: 1s - loss: 0.0603 - acc: 1.000 - ETA: 1s - loss: 0.0601 - acc: 1.000 - ETA: 1s - loss: 0.0599 - acc: 1.000 - ETA: 1s - loss: 0.0596 - acc: 1.000 - ETA: 1s - loss: 0.0595 - acc: 1.000 - ETA: 1s - loss: 0.0592 - acc: 1.000 - ETA: 1s - loss: 0.0590 - acc: 1.000 - ETA: 1s - loss: 0.0588 - acc: 1.000 - ETA: 1s - loss: 0.0585 - acc: 1.000 - ETA: 1s - loss: 0.0583 - acc: 1.000 - ETA: 1s - loss: 0.0581 - acc: 1.000 - ETA: 1s - loss: 0.0578 - acc: 1.000 - ETA: 1s - loss: 0.0576 - acc: 1.000 - ETA: 1s - loss: 0.0574 - acc: 1.000 - ETA: 1s - loss: 0.0573 - acc: 1.000 - ETA: 1s - loss: 0.0570 - acc: 1.000 - ETA: 1s - loss: 0.0568 - acc: 1.000 - ETA: 1s - loss: 0.0566 - acc: 1.000 - ETA: 1s - loss: 0.0564 - acc: 1.000 - ETA: 0s - loss: 0.0562 - acc: 1.000 - ETA: 0s - loss: 0.0561 - acc: 1.000 - ETA: 0s - loss: 0.0559 - acc: 1.000 - ETA: 0s - loss: 0.0557 - acc: 1.000 - ETA: 0s - loss: 0.0555 - acc: 1.000 - ETA: 0s - loss: 0.0553 - acc: 1.000 - ETA: 0s - loss: 0.0551 - acc: 1.000 - ETA: 0s - loss: 0.0550 - acc: 1.000 - ETA: 0s - loss: 0.0548 - acc: 1.000 - ETA: 0s - loss: 0.0547 - acc: 1.000 - ETA: 0s - loss: 0.0545 - acc: 1.000 - ETA: 0s - loss: 0.0543 - acc: 1.000 - ETA: 0s - loss: 0.0541 - acc: 1.000 - ETA: 0s - loss: 0.0539 - acc: 1.000 - ETA: 0s - loss: 0.0538 - acc: 1.000 - ETA: 0s - loss: 0.0536 - acc: 1.000 - ETA: 0s - loss: 0.0534 - acc: 1.000 - ETA: 0s - loss: 0.0532 - acc: 1.000 - ETA: 0s - loss: 0.0530 - acc: 1.000 - ETA: 0s - loss: 0.0528 - acc: 1.000 - ETA: 0s - loss: 0.0526 - acc: 1.000 - 4s 41us/step - loss: 0.0525 - acc: 1.0000\n",
      "Epoch 7/9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - ETA: 28s - loss: 0.0459 - acc: 1.00 - ETA: 4s - loss: 0.0386 - acc: 1.0000 - ETA: 4s - loss: 0.0387 - acc: 1.000 - ETA: 4s - loss: 0.0393 - acc: 1.000 - ETA: 4s - loss: 0.0388 - acc: 1.000 - ETA: 4s - loss: 0.0384 - acc: 1.000 - ETA: 4s - loss: 0.0380 - acc: 1.000 - ETA: 3s - loss: 0.0377 - acc: 1.000 - ETA: 3s - loss: 0.0375 - acc: 1.000 - ETA: 3s - loss: 0.0374 - acc: 1.000 - ETA: 3s - loss: 0.0372 - acc: 1.000 - ETA: 3s - loss: 0.0370 - acc: 1.000 - ETA: 3s - loss: 0.0369 - acc: 1.000 - ETA: 3s - loss: 0.0369 - acc: 1.000 - ETA: 3s - loss: 0.0368 - acc: 1.000 - ETA: 3s - loss: 0.0367 - acc: 1.000 - ETA: 3s - loss: 0.0366 - acc: 1.000 - ETA: 3s - loss: 0.0366 - acc: 1.000 - ETA: 3s - loss: 0.0365 - acc: 1.000 - ETA: 3s - loss: 0.0364 - acc: 1.000 - ETA: 3s - loss: 0.0363 - acc: 1.000 - ETA: 3s - loss: 0.0362 - acc: 1.000 - ETA: 3s - loss: 0.0361 - acc: 1.000 - ETA: 3s - loss: 0.0360 - acc: 1.000 - ETA: 3s - loss: 0.0359 - acc: 1.000 - ETA: 2s - loss: 0.0358 - acc: 1.000 - ETA: 2s - loss: 0.0357 - acc: 1.000 - ETA: 2s - loss: 0.0356 - acc: 1.000 - ETA: 2s - loss: 0.0355 - acc: 1.000 - ETA: 2s - loss: 0.0354 - acc: 1.000 - ETA: 2s - loss: 0.0352 - acc: 1.000 - ETA: 2s - loss: 0.0352 - acc: 1.000 - ETA: 2s - loss: 0.0350 - acc: 1.000 - ETA: 2s - loss: 0.0350 - acc: 1.000 - ETA: 2s - loss: 0.0348 - acc: 1.000 - ETA: 2s - loss: 0.0348 - acc: 1.000 - ETA: 2s - loss: 0.0347 - acc: 1.000 - ETA: 2s - loss: 0.0346 - acc: 1.000 - ETA: 2s - loss: 0.0345 - acc: 1.000 - ETA: 2s - loss: 0.0344 - acc: 1.000 - ETA: 2s - loss: 0.0343 - acc: 1.000 - ETA: 2s - loss: 0.0342 - acc: 1.000 - ETA: 2s - loss: 0.0341 - acc: 1.000 - ETA: 2s - loss: 0.0340 - acc: 1.000 - ETA: 1s - loss: 0.0339 - acc: 1.000 - ETA: 1s - loss: 0.0338 - acc: 1.000 - ETA: 1s - loss: 0.0337 - acc: 1.000 - ETA: 1s - loss: 0.0336 - acc: 1.000 - ETA: 1s - loss: 0.0335 - acc: 1.000 - ETA: 1s - loss: 0.0334 - acc: 1.000 - ETA: 1s - loss: 0.0333 - acc: 1.000 - ETA: 1s - loss: 0.0332 - acc: 1.000 - ETA: 1s - loss: 0.0331 - acc: 1.000 - ETA: 1s - loss: 0.0330 - acc: 1.000 - ETA: 1s - loss: 0.0330 - acc: 1.000 - ETA: 1s - loss: 0.0329 - acc: 1.000 - ETA: 1s - loss: 0.0328 - acc: 1.000 - ETA: 1s - loss: 0.0327 - acc: 1.000 - ETA: 1s - loss: 0.0326 - acc: 1.000 - ETA: 1s - loss: 0.0325 - acc: 1.000 - ETA: 1s - loss: 0.0324 - acc: 1.000 - ETA: 1s - loss: 0.0324 - acc: 1.000 - ETA: 1s - loss: 0.0323 - acc: 1.000 - ETA: 0s - loss: 0.0322 - acc: 1.000 - ETA: 0s - loss: 0.0321 - acc: 1.000 - ETA: 0s - loss: 0.0320 - acc: 1.000 - ETA: 0s - loss: 0.0320 - acc: 1.000 - ETA: 0s - loss: 0.0319 - acc: 1.000 - ETA: 0s - loss: 0.0318 - acc: 1.000 - ETA: 0s - loss: 0.0317 - acc: 1.000 - ETA: 0s - loss: 0.0316 - acc: 1.000 - ETA: 0s - loss: 0.0315 - acc: 1.000 - ETA: 0s - loss: 0.0315 - acc: 1.000 - ETA: 0s - loss: 0.0314 - acc: 1.000 - ETA: 0s - loss: 0.0313 - acc: 1.000 - ETA: 0s - loss: 0.0312 - acc: 1.000 - ETA: 0s - loss: 0.0311 - acc: 1.000 - ETA: 0s - loss: 0.0311 - acc: 1.000 - ETA: 0s - loss: 0.0310 - acc: 1.000 - ETA: 0s - loss: 0.0309 - acc: 1.000 - ETA: 0s - loss: 0.0309 - acc: 1.000 - ETA: 0s - loss: 0.0308 - acc: 1.000 - 4s 42us/step - loss: 0.0308 - acc: 1.0000\n",
      "Epoch 8/9\n",
      "100000/100000 [==============================] - ETA: 24s - loss: 0.0216 - acc: 1.00 - ETA: 4s - loss: 0.0252 - acc: 1.0000 - ETA: 4s - loss: 0.0253 - acc: 1.000 - ETA: 3s - loss: 0.0251 - acc: 1.000 - ETA: 3s - loss: 0.0250 - acc: 1.000 - ETA: 3s - loss: 0.0248 - acc: 1.000 - ETA: 3s - loss: 0.0247 - acc: 1.000 - ETA: 3s - loss: 0.0246 - acc: 1.000 - ETA: 3s - loss: 0.0245 - acc: 1.000 - ETA: 3s - loss: 0.0245 - acc: 1.000 - ETA: 3s - loss: 0.0245 - acc: 1.000 - ETA: 3s - loss: 0.0243 - acc: 1.000 - ETA: 3s - loss: 0.0243 - acc: 1.000 - ETA: 3s - loss: 0.0242 - acc: 1.000 - ETA: 3s - loss: 0.0241 - acc: 1.000 - ETA: 3s - loss: 0.0240 - acc: 1.000 - ETA: 3s - loss: 0.0240 - acc: 1.000 - ETA: 3s - loss: 0.0239 - acc: 1.000 - ETA: 3s - loss: 0.0239 - acc: 1.000 - ETA: 3s - loss: 0.0239 - acc: 1.000 - ETA: 3s - loss: 0.0238 - acc: 1.000 - ETA: 3s - loss: 0.0237 - acc: 1.000 - ETA: 3s - loss: 0.0237 - acc: 1.000 - ETA: 3s - loss: 0.0237 - acc: 1.000 - ETA: 3s - loss: 0.0237 - acc: 1.000 - ETA: 3s - loss: 0.0236 - acc: 1.000 - ETA: 3s - loss: 0.0236 - acc: 1.000 - ETA: 3s - loss: 0.0235 - acc: 1.000 - ETA: 3s - loss: 0.0235 - acc: 1.000 - ETA: 2s - loss: 0.0234 - acc: 1.000 - ETA: 2s - loss: 0.0233 - acc: 1.000 - ETA: 2s - loss: 0.0233 - acc: 1.000 - ETA: 2s - loss: 0.0233 - acc: 1.000 - ETA: 2s - loss: 0.0232 - acc: 1.000 - ETA: 2s - loss: 0.0232 - acc: 1.000 - ETA: 2s - loss: 0.0231 - acc: 1.000 - ETA: 2s - loss: 0.0230 - acc: 1.000 - ETA: 2s - loss: 0.0230 - acc: 1.000 - ETA: 2s - loss: 0.0230 - acc: 1.000 - ETA: 2s - loss: 0.0229 - acc: 1.000 - ETA: 2s - loss: 0.0229 - acc: 1.000 - ETA: 2s - loss: 0.0228 - acc: 1.000 - ETA: 2s - loss: 0.0228 - acc: 1.000 - ETA: 2s - loss: 0.0227 - acc: 1.000 - ETA: 2s - loss: 0.0227 - acc: 1.000 - ETA: 1s - loss: 0.0226 - acc: 1.000 - ETA: 1s - loss: 0.0225 - acc: 1.000 - ETA: 1s - loss: 0.0225 - acc: 1.000 - ETA: 1s - loss: 0.0224 - acc: 1.000 - ETA: 1s - loss: 0.0223 - acc: 1.000 - ETA: 1s - loss: 0.0223 - acc: 1.000 - ETA: 1s - loss: 0.0222 - acc: 1.000 - ETA: 1s - loss: 0.0222 - acc: 1.000 - ETA: 1s - loss: 0.0221 - acc: 1.000 - ETA: 1s - loss: 0.0221 - acc: 1.000 - ETA: 1s - loss: 0.0220 - acc: 1.000 - ETA: 1s - loss: 0.0219 - acc: 1.000 - ETA: 1s - loss: 0.0219 - acc: 1.000 - ETA: 0s - loss: 0.0219 - acc: 1.000 - ETA: 0s - loss: 0.0218 - acc: 1.000 - ETA: 0s - loss: 0.0218 - acc: 1.000 - ETA: 0s - loss: 0.0217 - acc: 1.000 - ETA: 0s - loss: 0.0216 - acc: 1.000 - ETA: 0s - loss: 0.0216 - acc: 1.000 - ETA: 0s - loss: 0.0215 - acc: 1.000 - ETA: 0s - loss: 0.0215 - acc: 1.000 - ETA: 0s - loss: 0.0214 - acc: 1.000 - ETA: 0s - loss: 0.0214 - acc: 1.000 - ETA: 0s - loss: 0.0213 - acc: 1.000 - ETA: 0s - loss: 0.0213 - acc: 1.000 - ETA: 0s - loss: 0.0212 - acc: 1.000 - ETA: 0s - loss: 0.0212 - acc: 1.000 - ETA: 0s - loss: 0.0211 - acc: 1.000 - ETA: 0s - loss: 0.0211 - acc: 1.000 - 4s 38us/step - loss: 0.0210 - acc: 1.0000\n",
      "Epoch 9/9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - ETA: 28s - loss: 0.0182 - acc: 1.00 - ETA: 3s - loss: 0.0178 - acc: 1.0000 - ETA: 3s - loss: 0.0178 - acc: 1.000 - ETA: 3s - loss: 0.0180 - acc: 1.000 - ETA: 3s - loss: 0.0180 - acc: 1.000 - ETA: 2s - loss: 0.0180 - acc: 1.000 - ETA: 2s - loss: 0.0178 - acc: 1.000 - ETA: 2s - loss: 0.0178 - acc: 1.000 - ETA: 2s - loss: 0.0178 - acc: 1.000 - ETA: 2s - loss: 0.0177 - acc: 1.000 - ETA: 2s - loss: 0.0176 - acc: 1.000 - ETA: 2s - loss: 0.0176 - acc: 1.000 - ETA: 2s - loss: 0.0175 - acc: 1.000 - ETA: 2s - loss: 0.0174 - acc: 1.000 - ETA: 2s - loss: 0.0174 - acc: 1.000 - ETA: 2s - loss: 0.0173 - acc: 1.000 - ETA: 2s - loss: 0.0172 - acc: 1.000 - ETA: 2s - loss: 0.0172 - acc: 1.000 - ETA: 2s - loss: 0.0172 - acc: 1.000 - ETA: 2s - loss: 0.0171 - acc: 1.000 - ETA: 2s - loss: 0.0171 - acc: 1.000 - ETA: 2s - loss: 0.0171 - acc: 1.000 - ETA: 2s - loss: 0.0171 - acc: 1.000 - ETA: 1s - loss: 0.0170 - acc: 1.000 - ETA: 1s - loss: 0.0170 - acc: 1.000 - ETA: 1s - loss: 0.0170 - acc: 1.000 - ETA: 1s - loss: 0.0169 - acc: 1.000 - ETA: 1s - loss: 0.0169 - acc: 1.000 - ETA: 1s - loss: 0.0168 - acc: 1.000 - ETA: 1s - loss: 0.0168 - acc: 1.000 - ETA: 1s - loss: 0.0168 - acc: 1.000 - ETA: 1s - loss: 0.0167 - acc: 1.000 - ETA: 1s - loss: 0.0167 - acc: 1.000 - ETA: 1s - loss: 0.0166 - acc: 1.000 - ETA: 1s - loss: 0.0166 - acc: 1.000 - ETA: 1s - loss: 0.0166 - acc: 1.000 - ETA: 1s - loss: 0.0165 - acc: 1.000 - ETA: 1s - loss: 0.0165 - acc: 1.000 - ETA: 1s - loss: 0.0165 - acc: 1.000 - ETA: 1s - loss: 0.0164 - acc: 1.000 - ETA: 1s - loss: 0.0164 - acc: 1.000 - ETA: 1s - loss: 0.0164 - acc: 1.000 - ETA: 0s - loss: 0.0163 - acc: 1.000 - ETA: 0s - loss: 0.0163 - acc: 1.000 - ETA: 0s - loss: 0.0163 - acc: 1.000 - ETA: 0s - loss: 0.0162 - acc: 1.000 - ETA: 0s - loss: 0.0162 - acc: 1.000 - ETA: 0s - loss: 0.0162 - acc: 1.000 - ETA: 0s - loss: 0.0161 - acc: 1.000 - ETA: 0s - loss: 0.0161 - acc: 1.000 - ETA: 0s - loss: 0.0161 - acc: 1.000 - ETA: 0s - loss: 0.0160 - acc: 1.000 - ETA: 0s - loss: 0.0160 - acc: 1.000 - ETA: 0s - loss: 0.0160 - acc: 1.000 - ETA: 0s - loss: 0.0159 - acc: 1.000 - ETA: 0s - loss: 0.0159 - acc: 1.000 - ETA: 0s - loss: 0.0159 - acc: 1.000 - ETA: 0s - loss: 0.0159 - acc: 1.000 - ETA: 0s - loss: 0.0158 - acc: 1.000 - ETA: 0s - loss: 0.0158 - acc: 1.000 - ETA: 0s - loss: 0.0158 - acc: 1.000 - 3s 31us/step - loss: 0.0157 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x288032ede80>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=9, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - ETA:  - 0s 28us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.011025202386081219, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
